# Tokenizer Concept
Tokenization is essentially splitting a phrase, sentence, paragraph, or entire text document into smaller units, such as individual words or terms. Each of these smaller units is called tokens.

## There is many application for Tokenization but I mentioned two examples here:
1- How to detect the number of Hashes and Mentions from tweets from Twitter
2- How to detect the Number written in hexadecimal after the hash sign
